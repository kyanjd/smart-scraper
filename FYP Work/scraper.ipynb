{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "import bs4\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoupScraper():\n",
    "    def __init__(self, url) -> None:\n",
    "        self.url = url\n",
    "        self.soup = None\n",
    "\n",
    "    def parse(self):\n",
    "        response = requests.get(self.url)\n",
    "        self.soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    def scrape_title(self):\n",
    "        # extracts title from the bs4 object and stores it in the info dictionary\n",
    "        if not self.soup:\n",
    "            raise NameError('The url is not parsed.')\n",
    "\n",
    "        self.title = self.soup.find('meta', {'name': 'citation_title'})['content']\n",
    "\n",
    "class SeleniumScraper():\n",
    "    def __init__(self, url, driver_path=None) -> None:\n",
    "        self.url = url\n",
    "        self.driver_path = driver_path\n",
    "        self.soup = None\n",
    "        self.title = None\n",
    "\n",
    "    def parse(self):\n",
    "        # loads a specific web page, scrapes HTML and stores it in a beautiful soup object\n",
    "        service = Service(executable_path=ChromeDriverManager().install())\n",
    "\n",
    "        # Load default profile\n",
    "        options = webdriver.ChromeOptions()\n",
    "        #options.add_argument(\"--headless\")\n",
    "\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "        driver.get(self.url)\n",
    "\n",
    "        source = driver.page_source\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "        self.soup = bs4.BeautifulSoup(source, \"html.parser\")\n",
    "    \n",
    "    def scrape_title(self):\n",
    "        # extracts title from the bs4 object and stores it in the info dictionary\n",
    "        if not self.soup:\n",
    "            raise NameError('The url is not parsed.')\n",
    "\n",
    "        self.title = self.soup.find('meta', {'name':\"citation_title\"})[\"content\"]\n",
    "    \n",
    "    def scrape_table(self):\n",
    "        # extracts variable/value pairs from tables in the bs4 object and stores them in the info dictionary\n",
    "        tables = self.soup.find_all('table')\n",
    "        print(\"p\")\n",
    "        print(tables)\n",
    "        for table in tables:\n",
    "            #print(table)\n",
    "            print(\"found \")\n",
    "            variables = [variable.contents for variable in table.thead.tr.find_all('th') if variable.contents]\n",
    "            values = []\n",
    "            trs = table.tbody.find_all('tr')\n",
    "\n",
    "            next = False\n",
    "            for tr in trs:\n",
    "                if next:\n",
    "                    variables += [variable.contents for variable in tr.find_all('td') if variable.contents]\n",
    "                    # print(variables)\n",
    "                    next = False\n",
    "                else:\n",
    "                    values += [value.contents[0] for value in tr.find_all('td') if value.contents]\n",
    "                    # print(values)\n",
    "                    next = True\n",
    "\n",
    "            print(variables)\n",
    "            print(values)\n",
    "\n",
    "            if len(variables) != len(values):\n",
    "                continue\n",
    "\n",
    "            for i in range(len(variables)):\n",
    "                try:\n",
    "                    float(values[i])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "                # name, unit, value = '', '', float(values[i])\n",
    "                # print(variables[i])\n",
    "\n",
    "                if isinstance(variables[i][0], bs4.element.Tag):\n",
    "                    # replace mathml with python\n",
    "                    mathml = variables[i][0].find('script', attrs={'id': re.compile(r'^MathJax')})\n",
    "                    # print(mathml)\n",
    "                    if mathml:\n",
    "                        mathml_expr = '<math xmlns=\"http://www.w3.org/1998/Math/MathML\">' + mathml.contents[0][6:]\n",
    "                        #tex_expr = self.converter.mml2tex(mathml_expr)[0]\n",
    "                        #ascii_expr = self.converter.tex2ascii(tex_expr)\n",
    "                        # python_expr = self.converter.ascii2python(ascii_expr)\n",
    "                        #variables[i][0] = ascii_expr\n",
    "\n",
    "                variables[i] = [str(v) for v in variables[i]]\n",
    "\n",
    "                expr = ''.join(variables[i])\n",
    "\n",
    "                # separate units\n",
    "                if expr[-1] == ')':\n",
    "                    idx = expr.rfind(' (')\n",
    "                    if idx <= 0:\n",
    "                        name = expr\n",
    "                        unit = 'Unknown'\n",
    "                    else:\n",
    "                        name = expr[:idx]\n",
    "                        unit = expr[idx+1:]\n",
    "                else:\n",
    "                    name = expr\n",
    "                    unit = 'Unknown'\n",
    "\n",
    "                #name = self.converter.name_post(name)\n",
    "                #unit = self.converter.unit_post(unit)\n",
    "\n",
    "                if not name[0].isdigit():\n",
    "                    self.info['var_dict'][' '.join([name, unit])] = float(values[i])\n",
    "\n",
    "            # print(variables)\n",
    "            # print(values)\n",
    "            # print(self.info['var_dict'])\n",
    "\n",
    "# soup_scraper = SoupScraper(\"https://www.sciencedirect.com/science/article/pii/S0749641904001664\")\n",
    "# soup_scraper.parse()\n",
    "# soup_scraper.scrape_title()\n",
    "# print(soup_scraper.soup)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_scraper = SeleniumScraper(url=\"https://www.sciencedirect.com/science/article/pii/S0749641904001664\", driver_path=\"C:\\\\Users\\\\kyanj\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "sel_scraper.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "[]\n",
      "An investigation of the effects of solution heat treatment on mechanical properties for AA 6xxx alloys: experimentation and modelling\n"
     ]
    }
   ],
   "source": [
    "sel_scraper.scrape_title()\n",
    "sel_scraper.scrape_table()\n",
    "print(sel_scraper.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0999999999999999\n"
     ]
    }
   ],
   "source": [
    "XX = 1.2\n",
    "YY = 1.1\n",
    "ZZ = 0.1\n",
    "\n",
    "value = XX\n",
    "value = value - YY\n",
    "print(f\"{value:.16f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
