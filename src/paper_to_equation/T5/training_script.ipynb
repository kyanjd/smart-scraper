{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from src.paper_to_equation.Generation.Equation_BaseDataset import BaseDataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import evaluate\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset: 100%|██████████| 1000/1000 [00:10<00:00, 91.22it/s]\n",
      "Generating dataset: 100%|██████████| 200/200 [00:02<00:00, 97.56it/s] \n",
      "Generating dataset: 100%|██████████| 200/200 [00:02<00:00, 96.52it/s] \n"
     ]
    }
   ],
   "source": [
    "class T5Dataset(BaseDataset):\n",
    "    def __init__(self, num):\n",
    "        super().__init__(num)\n",
    "\n",
    "    def get_columns(self):\n",
    "        return [\"MathML\", \"Python\"]\n",
    "\n",
    "t5_data = T5Dataset(1000)\n",
    "t5_data.create(\"Data/t5_train_2.csv\")\n",
    "t5_data = T5Dataset(200)\n",
    "t5_data.create(\"Data/t5_validation_2.csv\")\n",
    "t5_data = T5Dataset(200)\n",
    "t5_data.create(\"Data/t5_test_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "XMLSyntaxError",
     "evalue": "Opening and ending tag mismatch: mi line 11 and m, line 11, column 18 (<string>, line 11)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\kyanj\\anaconda3\\envs\\fyp_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[16], line 57\u001b[0m\n    sympy_expr = parse_mathml(mathml_expr)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[16], line 6\u001b[0m in \u001b[0;35mparse_mathml\u001b[0m\n    root = etree.fromstring(mathml)  # Parse XML\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32msrc\\\\lxml\\\\etree.pyx:3306\u001b[0m in \u001b[0;35mlxml.etree.fromstring\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32msrc\\\\lxml\\\\parser.pxi:1995\u001b[0m in \u001b[0;35mlxml.etree._parseMemoryDocument\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32msrc\\\\lxml\\\\parser.pxi:1875\u001b[0m in \u001b[0;35mlxml.etree._parseDoc\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32msrc\\\\lxml\\\\parser.pxi:1105\u001b[0m in \u001b[0;35mlxml.etree._BaseParser._parseUnicodeDoc\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32msrc\\\\lxml\\\\parser.pxi:633\u001b[0m in \u001b[0;35mlxml.etree._ParserContext._handleParseResultDoc\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32msrc\\\\lxml\\\\parser.pxi:743\u001b[0m in \u001b[0;35mlxml.etree._handleParseResult\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32msrc\\\\lxml\\\\parser.pxi:672\u001b[1;36m in \u001b[1;35mlxml.etree._raiseParseError\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>:11\u001b[1;36m\u001b[0m\n\u001b[1;31mXMLSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Opening and ending tag mismatch: mi line 11 and m, line 11, column 18\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, Eq, Add, Mul, Rational\n",
    "from lxml import etree\n",
    "\n",
    "# Recursive function to parse MathML into SymPy\n",
    "def parse_mathml(mathml):\n",
    "    root = etree.fromstring(mathml)  # Parse XML\n",
    "    return convert_to_sympy(root)\n",
    "\n",
    "def convert_to_sympy(element):\n",
    "    tag = element.tag.split(\"}\")[-1]  # Remove namespace (e.g., {MathML}mrow → mrow)\n",
    "\n",
    "    if tag == \"mi\":  # Variable (e.g., h, g, c)\n",
    "        return symbols(element.text)\n",
    "\n",
    "    elif tag == \"mo\":  # Operator (+, -, *, /, =)\n",
    "        return element.text.strip()\n",
    "\n",
    "    elif tag == \"msub\":  # Subscripted variables (e.g., h_g, h_c)\n",
    "        base, subscript = element.getchildren()\n",
    "        return symbols(f\"{convert_to_sympy(base)}_{convert_to_sympy(subscript)}\")\n",
    "\n",
    "    elif tag == \"mrow\":  # Math expressions inside <mrow>\n",
    "        children = element.getchildren()\n",
    "        expr = convert_to_sympy(children[0])\n",
    "        for i in range(1, len(children), 2):  # Operators appear at odd indices\n",
    "            op = convert_to_sympy(children[i])\n",
    "            right = convert_to_sympy(children[i + 1])\n",
    "            expr = {\n",
    "                \"=\": Eq,  # ✅ Correctly handles equations\n",
    "                \"+\": Add,\n",
    "                \"-\": lambda a, b: a - b,\n",
    "                \"*\": Mul,\n",
    "                \"/\": lambda a, b: Rational(a, b)\n",
    "            }.get(op, Add)(expr, right)\n",
    "        return expr\n",
    "\n",
    "    return None  # Fallback for unsupported cases\n",
    "\n",
    "# Example MathML input\n",
    "mathml_expr = '''\n",
    "<mrow xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "    <mi>h</mi>\n",
    "    <mo>=</mo>\n",
    "    <msub>\n",
    "        <mi>h</mi>\n",
    "        <mi>g</mi>\n",
    "    </msub>\n",
    "    <mo>+</mo>\n",
    "    <msub>\n",
    "        <mi>h</m>\n",
    "        <mi>c</mi>\n",
    "    </msub>\n",
    "</mrow>\n",
    "'''\n",
    "\n",
    "# Convert to SymPy expression\n",
    "sympy_expr = parse_mathml(mathml_expr)\n",
    "print(sympy_expr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=\n",
      "+\n",
      "h + h_c + h_g\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, Rational, Pow, Mul, Add\n",
    "from lxml import etree\n",
    "\n",
    "# Define a recursive function to parse MathML into SymPy\n",
    "def parse_mathml(mathml):\n",
    "    root = etree.fromstring(mathml)\n",
    "    return convert_to_sympy(root)\n",
    "\n",
    "def convert_to_sympy(element):\n",
    "    tag = element.tag.split(\"}\")[-1]  # Remove namespace (e.g., {http://www.w3.org/1998/Math/MathML}mrow → mrow)\n",
    "\n",
    "    if tag == \"mi\":  # Variable (x, y, h, etc.)\n",
    "        return symbols(element.text)\n",
    "\n",
    "    elif tag == \"mn\":  # Number (1, 2, etc.)\n",
    "        return Rational(element.text)\n",
    "\n",
    "    elif tag == \"mo\":  # Operator (+, -, *)\n",
    "        print(element.text.strip())\n",
    "        return element.text.strip()\n",
    "\n",
    "    elif tag == \"mfrac\":  # Fraction (a/b)\n",
    "        num, den = element.getchildren()\n",
    "        return Rational(convert_to_sympy(num), convert_to_sympy(den))\n",
    "\n",
    "    elif tag == \"msup\":  # Exponentiation (x^2)\n",
    "        base, exponent = element.getchildren()\n",
    "        return Pow(convert_to_sympy(base), convert_to_sympy(exponent))\n",
    "\n",
    "    elif tag == \"msub\":  # Subscripted variable (k_f, h_t, etc.)\n",
    "        base, subscript = element.getchildren()\n",
    "        return symbols(f\"{convert_to_sympy(base)}_{convert_to_sympy(subscript)}\")\n",
    "\n",
    "    elif tag == \"mrow\":  # Grouping of expressions (a + b)\n",
    "        children = element.getchildren()\n",
    "        expr = convert_to_sympy(children[0])\n",
    "        for i in range(1, len(children), 2):  # Every other element is an operator\n",
    "            op = convert_to_sympy(children[i])\n",
    "            right = convert_to_sympy(children[i + 1])\n",
    "            expr = {\"+\" : Add, \"-\" : Sub, \"*\" : Mul, \"/\" : Rational}.get(op, Add)(expr, right)\n",
    "        return expr\n",
    "\n",
    "    return None  # Fallback for unsupported cases\n",
    "\n",
    "# Example MathML Input (Super Complex Expression)\n",
    "mathml_expr = '''\n",
    "<mml:mrow xmlns:mml=\"http://www.w3.org/1998/Math/MathML\">\n",
    "    <mml:mi>h</mml:mi>\n",
    "    <mml:mo>=</mml:mo>\n",
    "    <mml:mfrac>\n",
    "        <mml:mrow>\n",
    "            <mml:mn>1</mml:mn>\n",
    "            <mml:mo>-</mml:mo>\n",
    "            <mml:mi>A</mml:mi>\n",
    "        </mml:mrow>\n",
    "        <mml:mrow>\n",
    "            <mml:msub>\n",
    "                <mml:mi>h</mml:mi>\n",
    "                <mml:mi>f</mml:mi>\n",
    "            </mml:msub>\n",
    "        </mml:mrow>\n",
    "    </mml:mfrac>\n",
    "    <mml:mfrac>\n",
    "        <mml:mrow>\n",
    "            <mml:mn>2</mml:mn>\n",
    "            <mml:msub>\n",
    "                <mml:mi>k</mml:mi>\n",
    "                <mml:mi>f</mml:mi>\n",
    "            </mml:msub>\n",
    "            <mml:msub>\n",
    "                <mml:mi>k</mml:mi>\n",
    "                <mml:mi>t</mml:mi>\n",
    "            </mml:msub>\n",
    "            <mml:msub>\n",
    "                <mml:mi>k</mml:mi>\n",
    "                <mml:mi>w</mml:mi>\n",
    "            </mml:msub>\n",
    "        </mml:mrow>\n",
    "        <mml:mrow>\n",
    "            <mml:mn>2</mml:mn>\n",
    "            <mml:msub>\n",
    "                <mml:mi>k</mml:mi>\n",
    "                <mml:mi>t</mml:mi>\n",
    "            </mml:msub>\n",
    "            <mml:msub>\n",
    "                <mml:mi>k</mml:mi>\n",
    "                <mml:mi>w</mml:mi>\n",
    "            </mml:msub>\n",
    "            <mml:mo>-</mml:mo>\n",
    "            <mml:msub>\n",
    "                <mml:mi>k</mml:mi>\n",
    "                <mml:mi>w</mml:mi>\n",
    "            </mml:msub>\n",
    "            <mml:msub>\n",
    "                <mml:mi>k</mml:mi>\n",
    "                <mml:mi>f</mml:mi>\n",
    "            </mml:msub>\n",
    "            <mml:mo>-</mml:mo>\n",
    "            <mml:msub>\n",
    "                <mml:mi>k</mml:mi>\n",
    "                <mml:mi>f</mml:mi>\n",
    "            </mml:msub>\n",
    "            <mml:msub>\n",
    "                <mml:mi>k</mml:mi>\n",
    "                <mml:mi>t</mml:mi>\n",
    "            </mml:msub>\n",
    "        </mml:mrow>\n",
    "    </mml:mfrac>\n",
    "</mml:mrow>\n",
    "'''\n",
    "mathml_expr = \"\"\"<mrow xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "    <mi>h</mi>\n",
    "    <mo>=</mo>\n",
    "    <msub>\n",
    "        <mi>h</mi>\n",
    "        <mi>g</mi>\n",
    "    </msub>\n",
    "    <mo>+</mo>\n",
    "    <msub>\n",
    "        <mi>h</mi>\n",
    "        <mi>c</mi>\n",
    "    </msub>\n",
    "</mrow>\"\"\"\n",
    "\n",
    "# Convert MathML to SymPy\n",
    "sympy_expr = parse_mathml(mathml_expr)\n",
    "print(sympy_expr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ab578bd2824797811139aa68062db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3803ca69404e66a4dd1fdf3b225cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afec3c06878b45a5bfd4e773510c1643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['MathML', 'Python'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['MathML', 'Python'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['MathML', 'Python'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MathML': '<mml:msub>\\n<mml:mi>N</mml:mi>\\n<mml:mi>P</mml:mi>\\n</mml:msub>\\n<mml:mo>=</mml:mo>\\n<mml:mrow>\\n<mml:munderover>\\n<mml:mo>∑</mml:mo>\\n<mml:mrow>\\n<mml:mi>t</mml:mi>\\n<mml:mo>=</mml:mo>\\n<mml:mn>7</mml:mn>\\n</mml:mrow>\\n<mml:msub>\\n<mml:mi>Ο</mml:mi>\\n<mml:mrow>\\n<mml:mi>O</mml:mi>\\n<mml:mi>ι</mml:mi>\\n<mml:mi>χ</mml:mi>\\n</mml:mrow>\\n</mml:msub>\\n</mml:munderover>\\n<mml:mfenced>\\n<mml:mrow>\\n<mml:msup>\\n<mml:msup>\\n<mml:mtext>exp</mml:mtext>\\n<mml:mi>φ</mml:mi>\\n</mml:msup>\\n<mml:msub>\\n<mml:mi>Μ</mml:mi>\\n<mml:mrow>\\n<mml:mi>ω</mml:mi>\\n<mml:mi>L</mml:mi>\\n</mml:mrow>\\n</mml:msub>\\n</mml:msup>\\n<mml:mo>+</mml:mo>\\n<mml:mrow>\\n<mml:mi>tan</mml:mi>\\n<mml:mfenced>\\n<mml:msub>\\n<mml:mi>η</mml:mi>\\n<mml:mrow>\\n<mml:mi>y</mml:mi>\\n<mml:mi>λ</mml:mi>\\n</mml:mrow>\\n</mml:msub>\\n</mml:mfenced>\\n</mml:mrow>\\n</mml:mrow>\\n</mml:mfenced>\\n</mml:mrow>',\n",
       " 'Python': \"N_P = Symbol('N_P')\\nt = Symbol('t')\\nΟ_Oιχ = Symbol('Ο_Oιχ')\\nΜ_ωL = Symbol('Μ_ωL')\\nφ = Symbol('φ')\\nη_yλ = Symbol('η_yλ')\\ne = Eq(N_P, Sum(exp(φ)**Μ_ωL + tan(η_yλ), (t, 7, Ο_Oιχ)))\"}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_files = {\"train\": \"Data/t5_train_2.csv\", \"validation\": \"Data/t5_validation_2.csv\", \"test\": \"Data/t5_test_2.csv\"}\n",
    "mml_py_dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "print(mml_py_dataset)\n",
    "display(mml_py_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5894b3aa124bbb8f38ddcaa8ac3092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7650bfb77bb547d2a861195cd9c69a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d5f4eea0ef40bab51e60f3278b459a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_checkpoint = \"t5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Tokenizer_Files/mathml-py-tokenizer-unigram-T5wrapped\", return_tensors=\"pt\")\n",
    "\n",
    "max_length = 1024\n",
    "def preprocess_function(examples):\n",
    "    prefix = \"translate MathML to Python: \"\n",
    "    inputs = [prefix + mml for mml in examples[\"MathML\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    labels = tokenizer(text_target=examples[\"Python\"], max_length=max_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = mml_py_dataset.map(preprocess_function, batched=True, remove_columns=[\"MathML\", \"Python\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'ra', 'n', 's', 'l', 'a', 'te', ' ', 'M', 'a', 't', 'h', 'M', 'L', ' ', 't', 'o', ' ', 'P', 'y', 't', 'h', 'o', 'n', ':', ' ', ':']\n"
     ]
    }
   ],
   "source": [
    "check = preprocess_function(mml_py_dataset[\"train\"][0])\n",
    "# print(check[\"labels\"])\n",
    "ids = check[\"input_ids\"][4]\n",
    "print(tokenizer.convert_ids_to_tokens(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75f1e1fe53b4bc5b5c95e8ea245a1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyanj\\anaconda3\\envs\\fyp_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kyanj\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a363ce9e326e4be1a2d7ed8bfdc6d6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90584fdf8434f17abdf09d42f1443e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 159,   21,   29,   21,   35,   36,   25,   34,   31,  253,   30,   32,\n",
      "           19,  162,   21,   29,   21,   35,   36,   25,   34,   31,  236,   30,\n",
      "           32,   19, 1513,  142,  125,   21,   29,   21,   35,   36,   25,   34,\n",
      "           31,   30, 1513,  142,  125,   30,   32,   19,   27,   21,   29,   21,\n",
      "           48,   47,  339,   41,   21,  214, 1379,   21,   49,   21,   57,   37,\n",
      "           31, 1513,  142,  125,   32,   41,   21, 1513,  142,  454, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
      "        [  26,   21,   29,   21,   35,   36,   25,   34,   31,   30,   26,   30,\n",
      "           32,   19,   22,   21,   29,   21,   35,   36,   25,   34,   31,   30,\n",
      "           22,   30,   32,   19, 1378,   33,   94,   21,   29,   21,   35,   36,\n",
      "           25,   34,   31,   30, 1378,   33,   94,   30,   32,   19,   27,   21,\n",
      "           29,   21,   48,   47,   31,   26,   41,   21,  260,   22,  173, 1378,\n",
      "           33,   94,   41,   21, 1378,   33,  589, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
      "        [ 134,   86,   94,  121,   21,   29,   21,   35,   36,   25,   34,   31,\n",
      "          248,   86,   94,  121,   30,   32,   19,  125,   21,   29,   21,   35,\n",
      "           36,   25,   34,   31,  246,   30,   32,   19,  150,   21,   29,   21,\n",
      "           35,   36,   25,   34,   31,  226,   30,   32,   19,  101,   21,   29,\n",
      "           21,   35,   36,   25,   34,   31,  240,   30,   32,   19,   27,   21,\n",
      "           29,   21,   48,   47,  336,   86,   94,  121,   41,   21, 1383,   57,\n",
      "           37,  642,   41,   21,  356,   41,   21,   74,   41,   21,  776]])\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "batch = data_collator([tokenized_dataset[\"train\"][i] for i in range(1,4)])\n",
    "print(batch[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 88.64759993490114,\n",
       " 'counts': [61, 59, 56, 53],\n",
       " 'totals': [66, 65, 64, 63],\n",
       " 'precisions': [92.42424242424242, 90.76923076923077, 87.5, 84.12698412698413],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 66,\n",
       " 'ref_len': 61}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "predictions = [\"η = Symbol('η')\\nη_0 = Symbol('η_0')\\nQ_η = Symbol('Q_η')\\nR = Symbol('R')\\nT = Symbol('T')\\ne = Eq(η, η_0*exp(((Q_η*T)/(R*T)))\"]\n",
    "references = [[\"η = Symbol('η')\\nη_0 = Symbol('η_0')\\nQ_η = Symbol('Q_η')\\nR = Symbol('R')\\nT = Symbol('T')\\ne = Eq(η, η_0*exp(Q_η/(R*T)))\"]]\n",
    "\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [label.strip() for label in decoded_labels]\n",
    "\n",
    "    # SacreBLEU\n",
    "    BLEUresult = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # Equation evaluation\n",
    "    \n",
    "\n",
    "    return {\"bleu\": BLEUresult[\"score\"]}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\kyanj\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "hf_login_key = os.environ.get(\"HF_LOGIN_KEY\")\n",
    "login(token=hf_login_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyanj\\anaconda3\\envs\\fyp_env\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"t5-small-mathml-to-python\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    args, \n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# trainer.evaluate(max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac12913ebd48442ebd509fa705191b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 17669.976, 'train_samples_per_second': 0.085, 'train_steps_per_second': 0.003, 'train_loss': 2.329975128173828, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=48, training_loss=2.329975128173828, metrics={'train_runtime': 17669.976, 'train_samples_per_second': 0.085, 'train_steps_per_second': 0.003, 'total_flos': 1311167215595520.0, 'train_loss': 2.329975128173828, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6c475023654f4f96b1ab6af28ed392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OverflowError",
     "evalue": "can't convert negative int to unsigned",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-base-mathml-to-python\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[0;32m      8\u001b[0m     model, \n\u001b[0;32m      9\u001b[0m     args, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m trainer\u001b[38;5;241m.\u001b[39mevaluate(max_length\u001b[38;5;241m=\u001b[39mmax_length)\n",
      "File \u001b[1;32mc:\\Users\\kyanj\\anaconda3\\envs\\fyp_env\\Lib\\site-packages\\transformers\\trainer_seq2seq.py:180\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mevaluate(eval_dataset, ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys, metric_key_prefix\u001b[38;5;241m=\u001b[39mmetric_key_prefix)\n",
      "File \u001b[1;32mc:\\Users\\kyanj\\anaconda3\\envs\\fyp_env\\Lib\\site-packages\\transformers\\trainer.py:3868\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3865\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3867\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3868\u001b[0m output \u001b[38;5;241m=\u001b[39m eval_loop(\n\u001b[0;32m   3869\u001b[0m     eval_dataloader,\n\u001b[0;32m   3870\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3871\u001b[0m     \u001b[38;5;66;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;00m\n\u001b[0;32m   3872\u001b[0m     \u001b[38;5;66;03m# self.args.prediction_loss_only\u001b[39;00m\n\u001b[0;32m   3873\u001b[0m     prediction_loss_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3874\u001b[0m     ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys,\n\u001b[0;32m   3875\u001b[0m     metric_key_prefix\u001b[38;5;241m=\u001b[39mmetric_key_prefix,\n\u001b[0;32m   3876\u001b[0m )\n\u001b[0;32m   3878\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   3879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32mc:\\Users\\kyanj\\anaconda3\\envs\\fyp_env\\Lib\\site-packages\\transformers\\trainer.py:4160\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4156\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[0;32m   4157\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[0;32m   4158\u001b[0m         )\n\u001b[0;32m   4159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4160\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels))\n\u001b[0;32m   4161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4162\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[1;34m(eval_preds)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m      4\u001b[0m     preds \u001b[38;5;241m=\u001b[39m preds[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m decoded_preds \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(preds, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Replace -100 in the labels as we can't decode them\u001b[39;00m\n\u001b[0;32m      9\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(labels \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, labels, tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id)\n",
      "File \u001b[1;32mc:\\Users\\kyanj\\anaconda3\\envs\\fyp_env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3959\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_decode\u001b[1;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m   3935\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[0;32m   3936\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3937\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3940\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   3942\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3943\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[0;32m   3944\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3957\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[0;32m   3958\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m   3960\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[0;32m   3961\u001b[0m             seq,\n\u001b[0;32m   3962\u001b[0m             skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[0;32m   3963\u001b[0m             clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[0;32m   3964\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3965\u001b[0m         )\n\u001b[0;32m   3966\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[0;32m   3967\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\kyanj\\anaconda3\\envs\\fyp_env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3960\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3935\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[0;32m   3936\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3937\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3940\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   3942\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3943\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[0;32m   3944\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3957\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[0;32m   3958\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m-> 3960\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[0;32m   3961\u001b[0m             seq,\n\u001b[0;32m   3962\u001b[0m             skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[0;32m   3963\u001b[0m             clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[0;32m   3964\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3965\u001b[0m         )\n\u001b[0;32m   3966\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[0;32m   3967\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\kyanj\\anaconda3\\envs\\fyp_env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3999\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m   3996\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[0;32m   3997\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[1;32m-> 3999\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[0;32m   4000\u001b[0m     token_ids\u001b[38;5;241m=\u001b[39mtoken_ids,\n\u001b[0;32m   4001\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[0;32m   4002\u001b[0m     clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[0;32m   4003\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4004\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kyanj\\anaconda3\\envs\\fyp_env\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:654\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    653\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[1;32m--> 654\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mdecode(token_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens)\n\u001b[0;32m    656\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    657\u001b[0m     clean_up_tokenization_spaces\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[0;32m    660\u001b[0m )\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[1;31mOverflowError\u001b[0m: can't convert negative int to unsigned"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "# Load trained model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base-mathml-to-python\")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    args, \n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.evaluate(max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '         '}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_checkpoint = \"t5-base-mathml-to-python\"\n",
    "translator = pipeline(\"text2text-generation\", model=model_checkpoint)\n",
    "result = translator(\"translate: MathML to Python: \\n<mml:mi>x</mml:mi>\\n<mml:mo>=</mml:mo>\\n<mml:mn>5</mml:mn>\")\n",
    "print(result)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<mml:mi>η</mml:mi>\\n<mml:mo>=</mml:mo>\\n<mml:mrow>\\n<mml:msub>\\n    <mml:mi>η</mml:mi>\\n    <mml:mi>0</mml:mi>\\n</mml:msub>\\n<mml:msup>\\n    <mml:mtext>exp</mml:mtext>\\n    <mml:mrow>\\n    <mml:mfrac>\\n        <mml:msub>\\n        <mml:mi>Q</mml:mi>\\n        <mml:mi>η</mml:mi>\\n        </mml:msub>\\n        <mml:mrow>\\n        <mml:mi>R</mml:mi>\\n        <mml:mi>T</mml:mi>\\n        </mml:mrow>\\n    </mml:mfrac>\\n    </mml:mrow>\\n</mml:msup>\\n</mml:mrow>'\n"
     ]
    }
   ],
   "source": [
    "string = \"\"\"<mml:mi>η</mml:mi>\n",
    "<mml:mo>=</mml:mo>\n",
    "<mml:mrow>\n",
    "<mml:msub>\n",
    "    <mml:mi>η</mml:mi>\n",
    "    <mml:mi>0</mml:mi>\n",
    "</mml:msub>\n",
    "<mml:msup>\n",
    "    <mml:mtext>exp</mml:mtext>\n",
    "    <mml:mrow>\n",
    "    <mml:mfrac>\n",
    "        <mml:msub>\n",
    "        <mml:mi>Q</mml:mi>\n",
    "        <mml:mi>η</mml:mi>\n",
    "        </mml:msub>\n",
    "        <mml:mrow>\n",
    "        <mml:mi>R</mml:mi>\n",
    "        <mml:mi>T</mml:mi>\n",
    "        </mml:mrow>\n",
    "    </mml:mfrac>\n",
    "    </mml:mrow>\n",
    "</mml:msup>\n",
    "</mml:mrow>\"\"\"\n",
    "\n",
    "print(repr(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'ra', 'n', 's', 'l', 'a', 'te', ':', ' ', 'M', 'a', 't', 'h', 'M', 'L', ' ', 't', 'o', ' ', 'P', 'y', 't', 'h', 'o', 'n', ':', ' ', '\\n', '<mml:mi>', 'h', '</mml:mi>', '\\n', '<mml:mo>', '=', '</mml:mo>', '\\n', '<mml:mrow>', '\\n', '<mml:msub>', '\\n', '<mml:mi>', 'h', '</mml:mi>', '\\n', '<mml:mi>', 'c', '</mml:mi>', '\\n', '</mml:msub>', '\\n', '<mml:mo>', '+', '</mml:mo>', '\\n', '<mml:msub>', '\\n', '<mml:mi>', 'h', '</mml:mi>', '\\n', '<mml:mi>', 'g', '</mml:mi>', '\\n', '</mml:msub>', '\\n', '</mml:mrow>', '\\n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyanj\\anaconda3\\envs\\fyp_env\\Lib\\site-packages\\transformers\\generation\\utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>: : : \n",
      "<mml:mi>: \n",
      "<mml:mi>: \n",
      "<mml:mi>: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"t5-small\"\n",
    "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"kj821/mathml-py-tokenizer-unigram-T5wrapped\")\n",
    "\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"kj821/t5-base-mathml-to-python\")\n",
    "\n",
    "text = \"\\n<mml:mi>h</mml:mi>\\n<mml:mo>=</mml:mo>\\n<mml:mrow>\\n<mml:msub>\\n<mml:mi>h</mml:mi>\\n<mml:mi>c</mml:mi>\\n</mml:msub>\\n<mml:mo>+</mml:mo>\\n<mml:msub>\\n<mml:mi>h</mml:mi>\\n<mml:mi>g</mml:mi>\\n</mml:msub>\\n</mml:mrow>\\n\"\n",
    "# text = \"I love going to the park on the weekend\"\n",
    "prefix = \"translate: MathML to Python: \"\n",
    "input_ids = tokenizer.encode(prefix + text, return_tensors=\"pt\")\n",
    "print(tokenizer.tokenize(prefix + text))\n",
    "check = tokenizer.decode(input_ids[0], skip_special_tokens=False)\n",
    "\n",
    "output_ids = model.generate(input_ids)\n",
    "output = tokenizer.decode(output_ids[0], skip_special_tokens=False, max_new_tokens=100)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
