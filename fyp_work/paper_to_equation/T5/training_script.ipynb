{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from fyp_work.paper_to_equation.generation.EquationGenerator import BaseDataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Dataset(BaseDataset):\n",
    "    def __init__(self, num, filepath):\n",
    "        super().__init__(num, filepath)\n",
    "\n",
    "    def get_columns(self):\n",
    "        return [\"MathML\", \"Python\"]\n",
    "\n",
    "t5_data = T5Dataset(100, \"t5_validation_1.csv\")\n",
    "t5_data.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['MathML', 'Python'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['MathML', 'Python'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['MathML', 'Python'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MathML': '\\n<mml:msup>\\n<mml:msup>\\n<mml:mtext>exp</mml:mtext>\\n<mml:mi>r</mml:mi>\\n</mml:msup>\\n<mml:msup>\\n<mml:mi>K</mml:mi>\\n<mml:msup>\\n<mml:mtext>exp</mml:mtext>\\n<mml:mrow>\\n<mml:mi>ι</mml:mi>\\n<mml:mi>ρ</mml:mi>\\n</mml:mrow>\\n</mml:msup>\\n</mml:msup>\\n</mml:msup>\\n<mml:mo>=</mml:mo>\\n<mml:mrow>\\n<mml:mi>cos</mml:mi>\\n<mml:mfenced>\\n<mml:mi>d</mml:mi>\\n</mml:mfenced>\\n</mml:mrow>\\n',\n",
       " 'Python': \"ι = Symbol('ι')\\nρ = Symbol('ρ')\\nK = Symbol('K')\\nr = Symbol('r')\\nd = Symbol('d')\\ne = Eq(exp(r)**(K**exp(ι*ρ)), cos(d))\"}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_files = {\"train\": \"t5_train_1.csv\", \"validation\": \"t5_validation_1.csv\", \"test\": \"t5_test_1.csv\"}\n",
    "mml_py_dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "# mml_py_dataset[\"validation\"] = mml_py_dataset.pop(\"test\")\n",
    "print(mml_py_dataset)\n",
    "\n",
    "# def add_task_prefix(example):\n",
    "#     task_prefix = \"translate: MathML to Python: \"\n",
    "#     example[\"MathML\"] = task_prefix + example[\"MathML\"]\n",
    "#     return example\n",
    "\n",
    "# mml_py_dataset = mml_py_dataset.map(add_task_prefix)\n",
    "display(mml_py_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb077ad60caa48a2ab57a0f8e28c06be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_checkpoint = \"t5-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")\n",
    "\n",
    "mml = mml_py_dataset[\"train\"][0][\"MathML\"]\n",
    "py = mml_py_dataset[\"train\"][0][\"Python\"]\n",
    "\n",
    "max_length = 1024\n",
    "def preprocess_function(examples):\n",
    "    prefix = \"translate: MathML to Python: \"\n",
    "    inputs = [prefix + mml for mml in examples[\"MathML\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    labels = tokenizer(text_target=examples[\"Python\"], max_length=max_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = mml_py_dataset.map(preprocess_function, batched=True, remove_columns=[\"MathML\", \"Python\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    3,   172,  3274,     3, 18650,   599,    31,   172,    31,    61,\n",
      "             3,    17,  3274,     3, 18650,   599,    31,    17,    31,    61,\n",
      "             3,     4,  3274,     3, 18650,   599,    31,     4,    31,    61,\n",
      "           454,  3274,     3, 18650,   599,    31,   566,    31,    61,     3,\n",
      "             2,  3274,     3, 18650,   599,    31,     2,    31,    61,     3,\n",
      "            15,  3274,   262,  1824,   599,  2152,   599,   172,    61,  1768,\n",
      "          4303,   599,    17,    61,    87,     4,     6,     3,    17,   152,\n",
      "           599,     2,    61, 19844,   994,   102,   599,   566,    61,    61,\n",
      "             1,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "        [  276,  3274,     3, 18650,   599,    31,   345,    31,    61,     3,\n",
      "             2,   834,     2,  3274,     3, 18650,   599,    31,     2,   834,\n",
      "             2,    31,    61,   445,   834,  1824,  3274,     3, 18650,   599,\n",
      "            31,   567,   834,  1824,    31,    61,   332,   834,     2,  3274,\n",
      "             3, 18650,   599,    31,   382,   834,     2,    31,    61,     3,\n",
      "             2,   834,     2,  3274,     3, 18650,   599,    31,     2,   834,\n",
      "             2,    31,    61,     3,   157,  3274,     3, 18650,   599,    31,\n",
      "           157,    31,    61,     3,     2,  3274,     3, 18650,   599,    31,\n",
      "             2,    31,    61,     3,    15,  3274,   262,  1824,   599,     7,\n",
      "          1824,    52,    17,   599,   345,    61,  1768,  4303,   599,     2,\n",
      "           834,     2,    61,    87,     7,  1824,    52,    17,   599,   567,\n",
      "           834,  1824,   201,     3,    18,   994,   102,   599,   382,   834,\n",
      "             2,  1935,     2,   834,     2,    61,  1768,  4303,   599,   157,\n",
      "            61,  1768,  3731,   599,     2,    61,    61,     1],\n",
      "        [  411,   834,   476,  3274,     3, 18650,   599,    31,   667,   834,\n",
      "           476,    31,    61,     3,     2,   834,     2,  3274,     3, 18650,\n",
      "           599,    31,     2,   834,     2,    31,    61,     3,     2,  3274,\n",
      "             3, 18650,   599,    31,     2,    31,    61,     3,    15,  3274,\n",
      "           262,  1824,   599,   509,     7,   599,   667,   834,   476,    61,\n",
      "          1768,   576,     7,   599,     2,   834,     2,   201,     3,     2,\n",
      "          1768,  4303,   599,   667,   834,   476,    61,    61,     1,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "batch = data_collator([tokenized_dataset[\"train\"][i] for i in range(1,4)])\n",
    "print(batch[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 88.64759993490114,\n",
       " 'counts': [61, 59, 56, 53],\n",
       " 'totals': [66, 65, 64, 63],\n",
       " 'precisions': [92.42424242424242, 90.76923076923077, 87.5, 84.12698412698413],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 66,\n",
       " 'ref_len': 61}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "predictions = [\"η = Symbol('η')\\nη_0 = Symbol('η_0')\\nQ_η = Symbol('Q_η')\\nR = Symbol('R')\\nT = Symbol('T')\\ne = Eq(η, η_0*exp(((Q_η*T)/(R*T)))\"]\n",
    "references = [[\"η = Symbol('η')\\nη_0 = Symbol('η_0')\\nQ_η = Symbol('Q_η')\\nR = Symbol('R')\\nT = Symbol('T')\\ne = Eq(η, η_0*exp(Q_η/(R*T)))\"]]\n",
    "\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [label.strip() for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"bleu\": result[\"score\"]}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d4c81548d7427180126fcb98feb0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyanj\\anaconda3\\envs\\fyp_env\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e1838ab1ef4c63ad5a5fda46fb9a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.2538156509399414,\n",
       " 'eval_model_preparation_time': 0.005,\n",
       " 'eval_bleu': 0.040544143328383735,\n",
       " 'eval_runtime': 492.3783,\n",
       " 'eval_samples_per_second': 0.203,\n",
       " 'eval_steps_per_second': 0.004}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"t5-base-mathml-to-python\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    args, \n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.evaluate(max_length=max_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
